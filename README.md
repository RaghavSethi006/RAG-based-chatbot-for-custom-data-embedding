ğŸ“š Streamlit RAG Chatbot App with Groq

This project is a Retrieval-Augmented Generation (RAG) pipeline built with Streamlit, LangChain, FAISS, and Groq LLMs.
It allows you to upload PDF documents, embed and store them, and query the content using a powerful language model backend.

ğŸš€ Features

Upload and parse PDF documents with PyMuPDF (fitz)

Split text using RecursiveCharacterTextSplitter

Generate vector embeddings with HuggingFaceEmbeddings

Store and query embeddings in a FAISS vector database

Ask natural language questions and get context-aware answers via Groq LLMs

Simple, interactive Streamlit web UI

ğŸ› ï¸ Tech Stack

Streamlit
 â€“ UI framework

LangChain
 â€“ RAG pipeline utilities

FAISS
 â€“ Vector search

HuggingFace Embeddings
 â€“ Embeddings

Groq
 â€“ LLM inference

PyMuPDF
 â€“ PDF parsing

ğŸ“‚ Project Structure
.
â”œâ”€â”€ app.py              # Main Streamlit app  
â”œâ”€â”€ requirements.txt    # Dependencies  
â”œâ”€â”€ .env                # API keys (Groq, HuggingFace, etc.)  
â””â”€â”€ vectorstore/        # FAISS index (auto-created after upload)  

4. Add environment variables

Create a .env file:

GROQ_API_KEY=your_groq_api_key
HF_MODEL=sentence-transformers/all-MiniLM-L6-v2

5. Run the app
streamlit run app.py

ğŸ¯ Usage

Open the Streamlit app in your browser

Upload one or more PDF files

Ask questions about the documents

Get AI-powered answers with citations from your PDFs

ğŸ”® Future Improvements

Add support for multiple embedding models

Implement persistent vector storage (e.g., Pinecone, Weaviate)

Add document summarization and chat history
